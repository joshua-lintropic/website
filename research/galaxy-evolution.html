<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Research – Prime Focus Spectrograph</title>

  <!-- favicon -->
  <link rel="shortcut icon" href="../assets/images/logo.ico" type="image/x-icon">

  <!-- core styles -->
  <link rel="stylesheet" href="../assets/css/style.css">

  <!-- google fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;500;600&display=swap" rel="stylesheet">

  <!-- latex support -->
  <script> window.MathJax = { chtml: { scale: 0.9 }, tex: { inlineMath: [['$', '$']] } }; </script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>

<body>
  <main>

    <!-- ───────────────── SIDEBAR ───────────────── -->
    <!-- identical markup copied from index.html for consistent styling -->
    <aside class="sidebar" data-sidebar>
      <div class="sidebar-info">
        <figure class="avatar-box">
          <img src="../assets/images/my-pfp.webp" alt="Joshua Lin" width="80" />
        </figure>
        <div class="info-content">
          <h1 class="name" title="Joshua Lin">Joshua Lin</h1>
          <p class="title">Aspiring Researcher</p>
        </div>
        <button class="info_more-btn" data-sidebar-btn>
          <span>Show Contacts</span>
          <ion-icon name="chevron-down"></ion-icon>
        </button>
      </div>
      <!-- …contacts + socials identical to index.html… -->
      <div class="sidebar-info_more">
        <div class="separator"></div>
        <ul class="contacts-list">
          <li class="contact-item">
            <div class="icon-box"><ion-icon name="mail-outline"></ion-icon></div>
            <div class="contact-info">
              <p class="contact-title">Email</p>
              <a href="mailto:joshua.lin@princeton.edu" class="contact-link">joshua.lin@princeton.edu</a>
            </div>
          </li>
          <li class="contact-item">
            <div class="icon-box"><ion-icon name="phone-portrait-outline"></ion-icon></div>
            <div class="contact-info">
              <p class="contact-title">Phone</p>
              <a href="tel:+15596910093" class="contact-link">+1&nbsp;(559)&nbsp;691‑0093</a>
            </div>
          </li>
          <li class="contact-item">
            <div class="icon-box"><ion-icon name="calendar-outline"></ion-icon></div>
            <div class="contact-info">
              <p class="contact-title">Birthday</p>
              <time datetime="2004-12-19">December&nbsp;19,&nbsp;2004</time>
            </div>
          </li>
          <li class="contact-item">
            <div class="icon-box"><ion-icon name="location-outline"></ion-icon></div>
            <div class="contact-info">
              <p class="contact-title">Location</p>
              <address>Princeton,&nbsp;NJ, USA</address>
            </div>
          </li>
        </ul>
        <div class="separator"></div>
        <ul class="social-list">
          <li class="social-item"><a href="https://www.facebook.com/joshua.lin.292350" class="social-link"><ion-icon name="logo-facebook"></ion-icon></a></li>
          <li class="social-item"><a href="https://www.linkedin.com/in/joshua-linsanity/" class="social-link"><ion-icon name="logo-linkedin"></ion-icon></a></li>
          <li class="social-item"><a href="https://www.instagram.com/perplexed._.panda/" class="social-link"><ion-icon name="logo-instagram"></ion-icon></a></li>
        </ul>
      </div>
    </aside>


    <!-- ──────────────── MAIN CONTENT ──────────────── -->
    <div class="main-content">

      <!-- NAVBAR -->
      <nav class="navbar">
        <ul class="navbar-list">
          <li class="navbar-item"><a href="/#about" class="navbar-link" data-nav-link>About</a></li>
          <li class="navbar-item"><a href="/#resume" class="navbar-link" data-nav-link>Resume</a></li>
          <li class="navbar-item"><a href="/#research" class="navbar-link" data-nav-link>Research</a></li>
          <li class="navbar-item"><a href="/#blog" class="navbar-link" data-nav-link>Blog</a></li>
          <!-- <li class="navbar-item"><a href="/#contact" class="navbar-link" data-nav-link>Contact</a></li> -->
        </ul>
      </nav>

      <!-- BLOG POST BODY -->
      <article class="about active" data-page="blog-post">
        <header>
          <h2 class="h2 article-title">Galaxy&nbsp;Evolution</h2>
        </header>
        <section class="about-text">

          <p>
            This page is currently under construction!
          </p>

          <p>
            <i>Published 2025-06-XX.</i>
          </p>

          <header>
            <h3>Introduction</h3>
          </header>
          <p>
            The Subaru Prime Focus Spectrograph at the Mauna Kea observatory in Hawai'i seeks to answer the following <a href="https://pfs.ipmu.jp/instrumentation.html">question</a>: <i>What aspects of large-scale cosmological structure drive the formation and evolution of galaxies?</i>  
          </p>
          <p>
            Researchers from <a href="https://pfs.ipmu.jp/people.html">all over the world</a> are working together to construct a first-of-its-kind instrument that can conduct a spectrographic survey "large enough" to precisely identify these causal relationships. Its observations will test our theories of dark matter, illuminate the life cycles of black holes, and trace "reionization" &mdash; the moment when the first stars flooded space with ultraviolet light, lifting the fog of the cosmic "dark ages."
          </p>

          <!-- <figure class="blog-post-image">
            <img src="galaxy-evolution/pfs-instrument.webp" alt="PFS instrument">
          </figure> -->

          <!-- <br> -->
          <!-- <br> -->
          <header>
            <h3>Problem</h3>
          </header>
          <p>
            For every night of scheduled observations, the PFS will conduct some small number of exposures $T \sim \mathcal{O}(10^1)$, during which each of $K \sim \mathcal{O}(10^3)$ fibers on the instrument will observe a galaxy. Each of $I \sim \mathcal{O}(10^5)$ galaxies are grouped by intrinsic astrophysical properties into <i>classes</i>, and a galaxy's class determines the integration time (i.e. number of exposures) required for it to be completely observed. Notably, any given fiber has access to <i>some</i>, but not necessarily all, galaxies. 
          </p>

          <p>
            Here is the principal question which I and my advisor, Peter Melchior, seek to address:
          </p>
          <blockquote>
            Given the global objective of balancing the proportion of completed galaxies per class, how can we optimally make local assignments of fibers to galaxies during each exposure? 
          </blockquote>

          <p>
            Explicitly, suppose we denote $\mathcal{I}$ the set of galaxies, $\mathcal{K}$ the set of fibers, and $\mathcal{L}$ the set of exposures. Let the galaxies be partitioned into $M$ classes $\{\Theta_m\}_{m \in \mathcal{M}}$, each with $N_m := |\Theta_m|$ galaxies, based on their shared required observation time $T_m$. Concretely, the problem we'd like to solve (henceforth denoted $\text{PFS}$) is
            <!-- (<a href="https://iopscience.iop.org/article/10.1088/2632-2153/ac4d12">Wang and Melchior 2022</a>) -->
          </p>
          <div class="problem-box">
            $$
            \text{PFS} := 
            \begin{cases}
            \begin{align}
            \operatorname*{maximize}_{\substack{t_{ikl} \in \{0,1\}}} \quad 
            & \min_{m \in \mathcal{M}} \Big\{ N_m^{-1} \sum_{i \in \Theta_m} \mathcal{X}_{[T_m, \infty)} \Big( \sum_{k \in \mathcal{K}} \sum_{l \in \mathcal{L}} t_{ikl} \Big) \Big\} \\
            \text{subject to} \quad 
            & t_{ikl} \leqslant \mathcal{X}_{\Psi_k}(i),\; \sum_{k \in \mathcal{K}} t_{ikl} \leqslant 1,\; \sum_{i \in \mathcal{I}} t_{ikl} \leqslant 1
            \end{align}
            \end{cases}
            $$
          </div>

          <p>
            where $\mathcal{X}$ is the <a href="https://en.wikipedia.org/wiki/Indicator_function">characteristic function</a>. It has an intuitive interpretation, despite its technical representation: 
          </p>
          <ul style="margin-left: 20px;">
            <li style="list-style-type: disc; display: list-item;">
              The scientific objective is an "equitable" distribution among the galaxy classes. It seeks to optimize the minimum fraction of galaxies completed in each class $m$ (i.e. $n_m / N_m$, where $n_m$ is the number of galaxies in $\Theta_m$ which receive at least $T_m$ observation time), across all classes. 
            </li>
          </ul>
          <ul style="margin-left: 20px;">
            <li style="list-style-type: disc; display: list-item;">
              The first constraint asks that each fiber $k$ only observes a predefined subset of galaxies $\Psi_k \subseteq \mathcal{I}$. 
            </li>
          </ul>
          <ul style="margin-left: 20px;">
            <li style="list-style-type: disc; display: list-item;">
              The second constraint asks that in each exposure, there is at most one fiber observing each galaxy. 
            </li>
          </ul>
          <ul style="margin-left: 20px;">
            <li style="list-style-type: disc; display: list-item;">
              The third constraint asks that in each exposure, each fiber observes at most one galaxy. 
            </li>
          </ul>

          <br>
          <p>
            This combinatorial optimization is extremely hard; in fact, it is <i>NP-hard</i>. Given the high-dimensional nature of the data (there are $IKL\sim \mathcal{O}(10^{10})$ binary decision variables!), brute force is effectively intractable. Instead, we'll need some more powerful tools with the right architecture to exploit this problem's discrete structure.
          </p>
          <!-- <br> -->

          <header>
            <h3>Class-Optimal Message Passing</h3>
          </header>

          <!-- <br> -->

          <header>
            <h4>What are MPNNs?</h4>
          </header>

          <p>
            Message-passing Neural Networks (MPNNs), introduced by <a href="https://arxiv.org/abs/1704.01212">Gilmer et. al.</a> at <a href="https://icml.cc/Conferences/2017/AcceptedPapers">ICML 2017</a> (and later generalized in <a href="https://arxiv.org/pdf/1806.01261">Battaglia et. al.'s</a> 2018 <code>graph-nets</code> paper) are a unified framework for interpreting learning on graphs. Let $G=(V,E)$ be an input graph represented by node features $\mathbf{h}_v^{(0)}$ and edge features $\mathbf{e}_{uv}$ for $u, v \in V$. Then learning proceeds through a sequence of $T$ discrete <i>message-passing</i> layers. In each layer $t$: 
          </p>

          <ol type="1">
            <li>
              <b>Message Phase:</b> for every edge $(u, v) \in E$, generate the message 
              $$
                \mathbf{m}_{uv}^{(t)} = M^{(t)}(\mathbf{h}_u^{(t-1)}, \mathbf{h}_v^{(t-1)}, \mathbf{e}_{uv})
              $$

              where $M^{(t)}$ is a learnable (often neural) function shared across edges. 
            </li>
            <li>
              <b>Aggregation Phase:</b> each node $v \in V$ aggregates incoming messages with a <i>permutation-invariant</i> operator $\phi$ such as a sum, mean, or max: 
              $$
                \mathbf{m}_v^{(t)} = \phi_{u \in \mathcal{N}(v)} \mathbf{m}_{uv}^{(t)}
              $$

              where $\mathcal{N}(\cdot)$ represents the neighborhood of its input (i.e., all connected objects). Permutation-invariance is critical so that the network doesn't associate the arbitrary ordering of the nodes as meaningful information.
            </li>
            <li>
              <b>Update Phase:</b> the node state is updated via another learnable function $U^{(t)}$:
              $$
                \mathbf{h}_v^{(t)} = U^{(t)}(\mathbf{h}_v^{(t-1)}, \mathbf{m}_v^{(t)})
              $$
            </li>
          </ol>

          <p>
            After $T$ rounds, the graph-level or node-level <i>readout</i> (e.g., pooling or attention) produces task-specific predictions, which can be used to calculate the objective and loss. 
          </p>

          <header>
            <h4>Modeling $\text{PFS}$ with MPNNs</h4>
          </header>

          <p>
            TODO. 
          </p>

          <!-- <br> -->
          <!-- <hr>
          <br> -->
          <!-- <p>
            Sources: 
          </p>
          <ul style="margin-left: 20px;">
            <li style="list-style-type: disc; display: list-item;">
              Figure 1: Kavli Institute, see https://pfs.ipmu.jp/instrumentation.html. 
            </li>
          </ul> -->
        </section>
      </article>

    </div><!-- /.main-content -->
  </main>

  <!-- core JS + icons (kept identical to index.html) -->
  <script src="../assets/js/script.js"></script>
  <script type="module" src="https://unpkg.com/ionicons@5.5.2/dist/ionicons/ionicons.esm.js"></script>
  <script nomodule src="https://unpkg.com/ionicons@5.5.2/dist/ionicons/ionicons.js"></script>
</body>

</html>
